{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "172d5a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                              Model  Year Status  \\\n",
      "0           0                              2022 Acura TLX A-Spec  2022    New   \n",
      "1           1                              2023 Acura RDX A-Spec  2023    New   \n",
      "2           2                              2023 Acura TLX Type S  2023    New   \n",
      "3           3                              2023 Acura TLX Type S  2023    New   \n",
      "4           4  2019 Acura MDX Sport Hybrid 3.0L w/Technology ...  2019   Used   \n",
      "\n",
      "         Mileage    Price             MSRP  \n",
      "0  Not available  $49,445     MSRP $49,445  \n",
      "1  Not available  $50,895    Not specified  \n",
      "2  Not available  $57,745    Not specified  \n",
      "3  Not available  $57,545    Not specified  \n",
      "4     32,675 mi.  $40,990  $600 price drop  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Reading csv file into dataframe\n",
    "df = pd.read_csv(\"car_data.csv\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31b35937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lokes\\AppData\\Local\\Temp\\ipykernel_23188\\244430637.py:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['Price'] = df['Price'].str.replace('$', '').str.replace(',', '')\n"
     ]
    }
   ],
   "source": [
    "#Preparing Price column\n",
    "df['Price'] = df['Price'].astype(str)\n",
    "df['Price'] = df['Price'].str.replace('$', '').str.replace(',', '')\n",
    "df['Price'] = pd.to_numeric(df['Price'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b799a1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0                                              Model  Year  \\\n",
      "0                0                              2022 Acura TLX A-Spec  2022   \n",
      "1                1                              2023 Acura RDX A-Spec  2023   \n",
      "2                2                              2023 Acura TLX Type S  2023   \n",
      "3                3                              2023 Acura TLX Type S  2023   \n",
      "4                4  2019 Acura MDX Sport Hybrid 3.0L w/Technology ...  2019   \n",
      "...            ...                                                ...   ...   \n",
      "115757       10005         2023 Volkswagen Atlas 3.6L SE w/Technology  2023   \n",
      "115758       10006                       2023 Volkswagen Taos 1.5T SE  2023   \n",
      "115759       10007                            2012 Volkswagen Beetle   2012   \n",
      "115760       10008                         2022 Volkswagen ID.4 Pro S  2022   \n",
      "115761       10009                      2013 Volkswagen Passat 2.5 SE  2013   \n",
      "\n",
      "       Status        Mileage    Price             MSRP  Acura Certified  \\\n",
      "0         New  Not available  49445.0     MSRP $49,445                0   \n",
      "1         New  Not available  50895.0    Not specified                0   \n",
      "2         New  Not available  57745.0    Not specified                0   \n",
      "3         New  Not available  57545.0    Not specified                0   \n",
      "4        Used     32,675 mi.  40990.0  $600 price drop                0   \n",
      "...       ...            ...      ...              ...              ...   \n",
      "115757    New  Not available  47346.0    Not specified                0   \n",
      "115758    New  Not available  30895.0    Not specified                0   \n",
      "115759   Used    100,395 mi.   9994.0  $252 price drop                0   \n",
      "115760    New  Not available  52585.0    Not specified                0   \n",
      "115761   Used    125,757 mi.  10995.0    Not specified                0   \n",
      "\n",
      "        BMW Certified  Chevrolet Certified  Dodge Certified  Ford Certified  \\\n",
      "0                   0                    0                0               0   \n",
      "1                   0                    0                0               0   \n",
      "2                   0                    0                0               0   \n",
      "3                   0                    0                0               0   \n",
      "4                   0                    0                0               0   \n",
      "...               ...                  ...              ...             ...   \n",
      "115757              0                    0                0               0   \n",
      "115758              0                    0                0               0   \n",
      "115759              0                    0                0               0   \n",
      "115760              0                    0                0               0   \n",
      "115761              0                    0                0               0   \n",
      "\n",
      "        INFINITI Certified  New  Porsche Certified  Toyota Certified  Used  \\\n",
      "0                        0    1                  0                 0     0   \n",
      "1                        0    1                  0                 0     0   \n",
      "2                        0    1                  0                 0     0   \n",
      "3                        0    1                  0                 0     0   \n",
      "4                        0    0                  0                 0     1   \n",
      "...                    ...  ...                ...               ...   ...   \n",
      "115757                   0    1                  0                 0     0   \n",
      "115758                   0    1                  0                 0     0   \n",
      "115759                   0    0                  0                 0     1   \n",
      "115760                   0    1                  0                 0     0   \n",
      "115761                   0    0                  0                 0     1   \n",
      "\n",
      "        Volkswagen Certified  \n",
      "0                          0  \n",
      "1                          0  \n",
      "2                          0  \n",
      "3                          0  \n",
      "4                          0  \n",
      "...                      ...  \n",
      "115757                     0  \n",
      "115758                     0  \n",
      "115759                     0  \n",
      "115760                     0  \n",
      "115761                     0  \n",
      "\n",
      "[115762 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "#Preparing Status column\n",
    "one_hot = pd.get_dummies(df['Status'])\n",
    "df = df.join(one_hot)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1554a2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lokes\\AppData\\Local\\Temp\\ipykernel_23188\\2268360427.py:6: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df2['Mileage_mean'] = df2['Mileage_mean'].str.replace(' mi.', '')\n",
      "C:\\Users\\lokes\\AppData\\Local\\Temp\\ipykernel_23188\\2268360427.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Mileage_mean'] = df2['Mileage_mean'].str.replace(' mi.', '')\n",
      "C:\\Users\\lokes\\AppData\\Local\\Temp\\ipykernel_23188\\2268360427.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Mileage_mean'] = df2['Mileage_mean'].str.replace(',', '').astype(float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48088.248784870535\n",
      "0          48088.248785\n",
      "1          48088.248785\n",
      "2          48088.248785\n",
      "3          48088.248785\n",
      "4          32675.000000\n",
      "              ...      \n",
      "115757     48088.248785\n",
      "115758     48088.248785\n",
      "115759    100395.000000\n",
      "115760     48088.248785\n",
      "115761    125757.000000\n",
      "Name: Mileage, Length: 115762, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Preparing Mileage Column\n",
    "df['Mileage_mean'] = df['Mileage'].copy()\n",
    "df['Mileage_mean'] = df['Mileage_mean'].replace('Not available', np.nan)\n",
    "\n",
    "df2 = df.dropna(subset=['Mileage_mean'])\n",
    "df2['Mileage_mean'] = df2['Mileage_mean'].str.replace(' mi.', '')\n",
    "df2['Mileage_mean'] = df2['Mileage_mean'].str.replace(',', '').astype(float)\n",
    "mean_mileage = df2['Mileage_mean'].mean()\n",
    "print(mean_mileage)\n",
    "\n",
    "df['Mileage'] = df['Mileage'].replace('Not available', mean_mileage)\n",
    "\n",
    "def replace_mileage(value):\n",
    "    if isinstance(value, str):\n",
    "        return value.replace(' mi.', '')\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "df['Mileage'] = df['Mileage'].apply(replace_mileage)\n",
    "\n",
    "def replace_mileage_again(value):\n",
    "    if isinstance(value, str):\n",
    "        return value.replace(',', '')\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "df['Mileage'] = df['Mileage'].apply(replace_mileage_again).astype(float)\n",
    "print(df['Mileage'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37d599b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'Model', 'Year', 'Status', 'Mileage', 'Price', 'MSRP', 'Acura Certified', 'BMW Certified', 'Chevrolet Certified', 'Dodge Certified', 'Ford Certified', 'INFINITI Certified', 'New', 'Porsche Certified', 'Toyota Certified', 'Used', 'Volkswagen Certified', 'Mileage_mean']\n",
      "        Unnamed: 0                                              Model  Year  \\\n",
      "0                0                              2022 Acura TLX A-Spec  2022   \n",
      "1                1                              2023 Acura RDX A-Spec  2023   \n",
      "2                2                              2023 Acura TLX Type S  2023   \n",
      "3                3                              2023 Acura TLX Type S  2023   \n",
      "4                4  2019 Acura MDX Sport Hybrid 3.0L w/Technology ...  2019   \n",
      "...            ...                                                ...   ...   \n",
      "115757       10005         2023 Volkswagen Atlas 3.6L SE w/Technology  2023   \n",
      "115758       10006                       2023 Volkswagen Taos 1.5T SE  2023   \n",
      "115759       10007                            2012 Volkswagen Beetle   2012   \n",
      "115760       10008                         2022 Volkswagen ID.4 Pro S  2022   \n",
      "115761       10009                      2013 Volkswagen Passat 2.5 SE  2013   \n",
      "\n",
      "       Status        Mileage    Price             MSRP  Acura Certified  \\\n",
      "0         New   48088.248785  49445.0     MSRP $49,445                0   \n",
      "1         New   48088.248785  50895.0    Not specified                0   \n",
      "2         New   48088.248785  57745.0    Not specified                0   \n",
      "3         New   48088.248785  57545.0    Not specified                0   \n",
      "4        Used   32675.000000  40990.0  $600 price drop                0   \n",
      "...       ...            ...      ...              ...              ...   \n",
      "115757    New   48088.248785  47346.0    Not specified                0   \n",
      "115758    New   48088.248785  30895.0    Not specified                0   \n",
      "115759   Used  100395.000000   9994.0  $252 price drop                0   \n",
      "115760    New   48088.248785  52585.0    Not specified                0   \n",
      "115761   Used  125757.000000  10995.0    Not specified                0   \n",
      "\n",
      "        BMW Certified  Chevrolet Certified  Dodge Certified  Ford Certified  \\\n",
      "0                   0                    0                0               0   \n",
      "1                   0                    0                0               0   \n",
      "2                   0                    0                0               0   \n",
      "3                   0                    0                0               0   \n",
      "4                   0                    0                0               0   \n",
      "...               ...                  ...              ...             ...   \n",
      "115757              0                    0                0               0   \n",
      "115758              0                    0                0               0   \n",
      "115759              0                    0                0               0   \n",
      "115760              0                    0                0               0   \n",
      "115761              0                    0                0               0   \n",
      "\n",
      "        INFINITI Certified  New  Porsche Certified  Toyota Certified  Used  \\\n",
      "0                        0    1                  0                 0     0   \n",
      "1                        0    1                  0                 0     0   \n",
      "2                        0    1                  0                 0     0   \n",
      "3                        0    1                  0                 0     0   \n",
      "4                        0    0                  0                 0     1   \n",
      "...                    ...  ...                ...               ...   ...   \n",
      "115757                   0    1                  0                 0     0   \n",
      "115758                   0    1                  0                 0     0   \n",
      "115759                   0    0                  0                 0     1   \n",
      "115760                   0    1                  0                 0     0   \n",
      "115761                   0    0                  0                 0     1   \n",
      "\n",
      "        Volkswagen Certified Mileage_mean  \n",
      "0                          0          NaN  \n",
      "1                          0          NaN  \n",
      "2                          0          NaN  \n",
      "3                          0          NaN  \n",
      "4                          0   32,675 mi.  \n",
      "...                      ...          ...  \n",
      "115757                     0          NaN  \n",
      "115758                     0          NaN  \n",
      "115759                     0  100,395 mi.  \n",
      "115760                     0          NaN  \n",
      "115761                     0  125,757 mi.  \n",
      "\n",
      "[115762 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "#Creating a list of all the column headings\n",
    "columns = df.columns.tolist()\n",
    "\n",
    "print(columns)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8ff05b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0      Year   Mileage     Price  Acura Certified  BMW Certified  \\\n",
      "0           0  0.986486  0.049357  0.019072                0              0   \n",
      "1           1  1.000000  0.049357  0.019653                0              0   \n",
      "2           2  1.000000  0.049357  0.022395                0              0   \n",
      "3           3  1.000000  0.049357  0.022315                0              0   \n",
      "4           4  0.945946  0.033537  0.015688                0              0   \n",
      "\n",
      "   Chevrolet Certified  Dodge Certified  Ford Certified  INFINITI Certified  \\\n",
      "0                    0                0               0                   0   \n",
      "1                    0                0               0                   0   \n",
      "2                    0                0               0                   0   \n",
      "3                    0                0               0                   0   \n",
      "4                    0                0               0                   0   \n",
      "\n",
      "   New  Porsche Certified  Toyota Certified  Used  Volkswagen Certified  \n",
      "0    1                  0                 0     0                     0  \n",
      "1    1                  0                 0     0                     0  \n",
      "2    1                  0                 0     0                     0  \n",
      "3    1                  0                 0     0                     0  \n",
      "4    0                  0                 0     1                     0  \n"
     ]
    }
   ],
   "source": [
    "#Normalizing the dataframe\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "df3 = df.loc[:, ['Unnamed: 0',  'Year',  'Mileage', 'Price',  'Acura Certified', 'BMW Certified', 'Chevrolet Certified', 'Dodge Certified', 'Ford Certified', 'INFINITI Certified', 'New', 'Porsche Certified', 'Toyota Certified', 'Used', 'Volkswagen Certified']].copy()\n",
    "df3 = df3.dropna()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = df3.copy()\n",
    "df_normalized['Year'] = scaler.fit_transform(df_normalized[['Year']])\n",
    "df_normalized['Mileage'] = scaler.fit_transform(df_normalized[['Mileage']])\n",
    "df_normalized['Price'] = scaler.fit_transform(df_normalized[['Price']])\n",
    "\n",
    "print(df_normalized.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14e5ba51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Linear Regression: 0.012472013610304509\n"
     ]
    }
   ],
   "source": [
    "#Applying Linear Regression algorithm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = df_normalized.drop([\"Price\"], axis = 1)\n",
    "y = df_normalized[\"Price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "y_pred = LR.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE for Linear Regression:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c3f82511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\lokes\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for Linear Regression: {'fit_intercept': False, 'normalize': True}\n",
      "RMSE for Linear Regression after tuning Hyperparameters: 0.012472013610304509\n"
     ]
    }
   ],
   "source": [
    "#Applying Grid Search to tune hyperparameters of Linear Regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "X = df_normalized.drop([\"Price\"], axis = 1)\n",
    "y = df_normalized[\"Price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "LR = LinearRegression()\n",
    "\n",
    "param_grid = {'fit_intercept': [True, False], 'normalize': [True, False]}\n",
    "\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared = False)\n",
    "\n",
    "grid_search = GridSearchCV(LR, param_grid, cv = 5, scoring = rmse_scorer)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Best hyperparameters for Linear Regression:', grid_search.best_params_)\n",
    "\n",
    "LR_grid = grid_search.best_estimator_\n",
    "y_pred = LR_grid.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "print('RMSE for Linear Regression after tuning Hyperparameters:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a94eb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Polynomial Regression: 0.012275530926750797\n"
     ]
    }
   ],
   "source": [
    "#Applying Polynomial Regression\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "PR = PolynomialFeatures(degree = 2)\n",
    "X_train_poly = PR.fit_transform(X_train)\n",
    "\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train_poly, y_train)\n",
    "\n",
    "X_test_poly = PR.transform(X_test)\n",
    "y_pred = LR.predict(X_test_poly)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE for Polynomial Regression:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cde45d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best degree: 3\n",
      "RMSE for Polynomial Regression after tuning Hyperparameters: 0.01317427074970023\n"
     ]
    }
   ],
   "source": [
    "#Applying GridSearch to tune Hyperparameters before applying Polynomial Regression\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "PR = PolynomialFeatures()\n",
    "pipeline = make_pipeline(PR, LinearRegression())\n",
    "param_grid = {'polynomialfeatures__degree': [1, 2, 3]}\n",
    "\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared = False)\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid = param_grid, cv = 5, scoring = rmse_scorer)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best degree:\", grid_search.best_params_['polynomialfeatures__degree'])\n",
    "\n",
    "poly_grid = PolynomialFeatures(degree = grid_search.best_params_['polynomialfeatures__degree'])\n",
    "X_train_poly = poly_grid.fit_transform(X_train)\n",
    "\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train_poly, y_train)\n",
    "\n",
    "X_test_poly = poly_grid.transform(X_test)\n",
    "y_pred = LR.predict(X_test_poly)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(\"RMSE for Polynomial Regression after tuning Hyperparameters:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25f797df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Decision Tree Regression: 0.01640484283894998\n"
     ]
    }
   ],
   "source": [
    "#Applying Decision Tree Regression\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "DT = DecisionTreeRegressor()\n",
    "\n",
    "DT.fit(X_train, y_train)\n",
    "y_pred = DT.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "print('RMSE for Decision Tree Regression:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff143645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters for Decision Tree Regression: {'max_depth': 6, 'min_samples_leaf': 3}\n",
      "RMSE for Decision Tree Regression after tuning hyperparameters: 0.011983832023734653\n"
     ]
    }
   ],
   "source": [
    "#Applying GridSearch to tune Hyperparameters before applying Decision Tree Regression\n",
    "\n",
    "DT = DecisionTreeRegressor()\n",
    "\n",
    "param_grid = {'max_depth': [2, 4, 6], 'min_samples_leaf': [1, 2, 3]}\n",
    "\n",
    "grid_search = GridSearchCV(DT, param_grid, cv = 5, scoring = 'neg_root_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print('Best hyperparameters for Decision Tree Regression:', best_params)\n",
    "\n",
    "DT_grid = DecisionTreeRegressor(max_depth = best_params['max_depth'], min_samples_leaf = best_params['min_samples_leaf'])\n",
    "DT_grid.fit(X_train, y_train)\n",
    "\n",
    "y_pred = DT_grid.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "print('RMSE for Decision Tree Regression after tuning hyperparameters:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8b1087f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Random Forest Regression: 0.011931011496280487\n"
     ]
    }
   ],
   "source": [
    "#Applying Random Forest Regression\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "RF = RandomForestRegressor(n_estimators = 100, max_depth = 10, random_state = 42)\n",
    "\n",
    "RF.fit(X_train, y_train)\n",
    "y_pred = RF.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "print('RMSE for Random Forest Regression:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00c0f286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Random Forest Regression: {'max_depth': 5, 'n_estimators': 100}\n",
      "RMSE for Random Forest Regression after tuning hyperparameters: 0.01188988728031725\n"
     ]
    }
   ],
   "source": [
    "#Applying GridSearch to tune Hyperparameters before applying Random Forest Regression\n",
    "\n",
    "param_grid = {'n_estimators': [50, 100], 'max_depth': [5, 10, 20]}\n",
    "\n",
    "RF = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(estimator = RF, param_grid = param_grid, cv = 5, scoring = 'neg_root_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters for Random Forest Regression:\", best_params)\n",
    "\n",
    "RF_grid = RandomForestRegressor(n_estimators = best_params['n_estimators'], max_depth = best_params['max_depth'])\n",
    "\n",
    "RF_grid.fit(X_train, y_train)\n",
    "y_pred = RF_grid.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "print('RMSE for Random Forest Regression after tuning hyperparameters:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66ef3675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Support Vector Regression: 0.07362914897886248\n"
     ]
    }
   ],
   "source": [
    "#Applying Support Vector Regression\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "SV = SVR(kernel = 'rbf', C = 100, gamma = 0.1, epsilon = 0.1)\n",
    "\n",
    "SV.fit(X_train, y_train)\n",
    "y_pred = SV.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "print(\"RMSE for Support Vector Regression:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b21462",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying GridSearch to tune Hyperparameters before applying Support Vector Regression\n",
    "\n",
    "param_grid = {'kernel': ['linear', 'rbf'], 'C': [0.1, 1, 10], 'gamma': [0.01, 0.1, 1]}\n",
    "\n",
    "rmse_scorer = make_scorer(mean_squared_error, squared = False)\n",
    "\n",
    "grid_search = GridSearchCV(SV, param_grid, scoring = rmse_scorer, cv = 5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best hyperparameters for Support Vector Regression:\", grid_search.best_params_)\n",
    "\n",
    "SV_grid = SVR(kernel = 'rbf', C = 100, gamma = 0.1, epsilon = 0.1)\n",
    "\n",
    "SV_grid.fit(X_train, y_train)\n",
    "y_pred = SV_grid.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"RMSE for Support Vector Regression after tuning hyperparameters:\", rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
